{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9a869cf1",
   "metadata": {},
   "source": [
    "# 1. 환경 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a29731da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langgraph in /Users/jeong-ug/.pyenv/versions/anaconda3-2025.06-0/lib/python3.13/site-packages (1.0.1)\n",
      "Requirement already satisfied: langchain-core in /Users/jeong-ug/.pyenv/versions/anaconda3-2025.06-0/lib/python3.13/site-packages (0.3.79)\n",
      "Requirement already satisfied: langchain in /Users/jeong-ug/.pyenv/versions/anaconda3-2025.06-0/lib/python3.13/site-packages (0.3.27)\n",
      "Requirement already satisfied: langgraph-checkpoint<4.0.0,>=2.1.0 in /Users/jeong-ug/.pyenv/versions/anaconda3-2025.06-0/lib/python3.13/site-packages (from langgraph) (3.0.0)\n",
      "Requirement already satisfied: langgraph-prebuilt<1.1.0,>=1.0.0 in /Users/jeong-ug/.pyenv/versions/anaconda3-2025.06-0/lib/python3.13/site-packages (from langgraph) (1.0.1)\n",
      "Requirement already satisfied: langgraph-sdk<0.3.0,>=0.2.2 in /Users/jeong-ug/.pyenv/versions/anaconda3-2025.06-0/lib/python3.13/site-packages (from langgraph) (0.2.9)\n",
      "Requirement already satisfied: pydantic>=2.7.4 in /Users/jeong-ug/.pyenv/versions/anaconda3-2025.06-0/lib/python3.13/site-packages (from langgraph) (2.12.3)\n",
      "Requirement already satisfied: xxhash>=3.5.0 in /Users/jeong-ug/.pyenv/versions/anaconda3-2025.06-0/lib/python3.13/site-packages (from langgraph) (3.6.0)\n",
      "Requirement already satisfied: ormsgpack>=1.10.0 in /Users/jeong-ug/.pyenv/versions/anaconda3-2025.06-0/lib/python3.13/site-packages (from langgraph-checkpoint<4.0.0,>=2.1.0->langgraph) (1.11.0)\n",
      "Requirement already satisfied: httpx>=0.25.2 in /Users/jeong-ug/.pyenv/versions/anaconda3-2025.06-0/lib/python3.13/site-packages (from langgraph-sdk<0.3.0,>=0.2.2->langgraph) (0.28.1)\n",
      "Requirement already satisfied: orjson>=3.10.1 in /Users/jeong-ug/.pyenv/versions/anaconda3-2025.06-0/lib/python3.13/site-packages (from langgraph-sdk<0.3.0,>=0.2.2->langgraph) (3.11.3)\n",
      "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in /Users/jeong-ug/.pyenv/versions/anaconda3-2025.06-0/lib/python3.13/site-packages (from langchain-core) (0.4.37)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /Users/jeong-ug/.pyenv/versions/anaconda3-2025.06-0/lib/python3.13/site-packages (from langchain-core) (9.0.0)\n",
      "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /Users/jeong-ug/.pyenv/versions/anaconda3-2025.06-0/lib/python3.13/site-packages (from langchain-core) (1.33)\n",
      "Requirement already satisfied: PyYAML<7.0.0,>=5.3.0 in /Users/jeong-ug/.pyenv/versions/anaconda3-2025.06-0/lib/python3.13/site-packages (from langchain-core) (6.0.2)\n",
      "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in /Users/jeong-ug/.pyenv/versions/anaconda3-2025.06-0/lib/python3.13/site-packages (from langchain-core) (4.15.0)\n",
      "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in /Users/jeong-ug/.pyenv/versions/anaconda3-2025.06-0/lib/python3.13/site-packages (from langchain-core) (24.2)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /Users/jeong-ug/.pyenv/versions/anaconda3-2025.06-0/lib/python3.13/site-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core) (2.1)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in /Users/jeong-ug/.pyenv/versions/anaconda3-2025.06-0/lib/python3.13/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core) (1.0.0)\n",
      "Requirement already satisfied: requests>=2.0.0 in /Users/jeong-ug/.pyenv/versions/anaconda3-2025.06-0/lib/python3.13/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core) (2.32.5)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in /Users/jeong-ug/.pyenv/versions/anaconda3-2025.06-0/lib/python3.13/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core) (0.23.0)\n",
      "Requirement already satisfied: anyio in /Users/jeong-ug/.pyenv/versions/anaconda3-2025.06-0/lib/python3.13/site-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (4.7.0)\n",
      "Requirement already satisfied: certifi in /Users/jeong-ug/.pyenv/versions/anaconda3-2025.06-0/lib/python3.13/site-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (2025.10.5)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/jeong-ug/.pyenv/versions/anaconda3-2025.06-0/lib/python3.13/site-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (1.0.9)\n",
      "Requirement already satisfied: idna in /Users/jeong-ug/.pyenv/versions/anaconda3-2025.06-0/lib/python3.13/site-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (3.7)\n",
      "Requirement already satisfied: h11>=0.16 in /Users/jeong-ug/.pyenv/versions/anaconda3-2025.06-0/lib/python3.13/site-packages (from httpcore==1.*->httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/jeong-ug/.pyenv/versions/anaconda3-2025.06-0/lib/python3.13/site-packages (from pydantic>=2.7.4->langgraph) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.4 in /Users/jeong-ug/.pyenv/versions/anaconda3-2025.06-0/lib/python3.13/site-packages (from pydantic>=2.7.4->langgraph) (2.41.4)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in /Users/jeong-ug/.pyenv/versions/anaconda3-2025.06-0/lib/python3.13/site-packages (from pydantic>=2.7.4->langgraph) (0.4.2)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.9 in /Users/jeong-ug/.pyenv/versions/anaconda3-2025.06-0/lib/python3.13/site-packages (from langchain) (0.3.11)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /Users/jeong-ug/.pyenv/versions/anaconda3-2025.06-0/lib/python3.13/site-packages (from langchain) (2.0.39)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Users/jeong-ug/.pyenv/versions/anaconda3-2025.06-0/lib/python3.13/site-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/jeong-ug/.pyenv/versions/anaconda3-2025.06-0/lib/python3.13/site-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core) (2.3.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /Users/jeong-ug/.pyenv/versions/anaconda3-2025.06-0/lib/python3.13/site-packages (from anyio->httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (1.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install langgraph langchain-core langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bae916c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 환경 변수 로드\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6bf2bee",
   "metadata": {},
   "source": [
    "# 2. 그래프 요소 정의\n",
    "## 1. 상태 작성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e34ea471",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict, Optional\n",
    "\n",
    "class AgentState(TypedDict):\n",
    "    user_input: str               # 사용자의 질문\n",
    "    draft_answer: Optional[str]   # 현재까지 생성된 답변\n",
    "    eval_result: Optional[str]    # 평가 결과(예: \"satisfied\" / \"unsatisfied\")\n",
    "    reasoning: Optional[str]      # 평가 과정 설명 (디버깅용, 최종 출력에는 안 써도 됨)\n",
    "    loop_count: int               # 몇 번째 루프인지\n",
    "    max_loops: int                # 최대 루프 횟수"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3349bdb",
   "metadata": {},
   "source": [
    "## 2. llm 호출 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0169f5ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_upstage import ChatUpstage\n",
    "from langchain.schema import SystemMessage, HumanMessage\n",
    "# from langchain_openai import ChatOpenAI\n",
    "\n",
    "# 1) 모델 인스턴스를 전역으로 한 번만 만들고 재사용합니다.\n",
    "llm = ChatUpstage(\n",
    "    model=\"solar-mini\",\n",
    "    temperature=0.7,\n",
    ")\n",
    "\n",
    "# llm_validate = ChatOpenAI(\n",
    "#     model=\"gpt-5-mini\"\n",
    "# )\n",
    "\n",
    "llm_validate = ChatUpstage(\n",
    "    model=\"solar-pro2\",\n",
    "    temperature=0.7\n",
    ")\n",
    "\n",
    "def call_llm(prompt: str) -> str:\n",
    "    \"\"\"\n",
    "    Upstage 모델을 한 번 호출하고 string만 돌려줍니다.\n",
    "    LangGraph 노드 안에서는 이 함수만 부릅니다.\n",
    "    \"\"\"\n",
    "    messages = [\n",
    "        SystemMessage(content=\"당신은 정중하고 정확하게 답변하는 전문가 어시스턴트입니다.\"),\n",
    "        HumanMessage(content=prompt),\n",
    "    ]\n",
    "\n",
    "    # invoke()는 ChatModel 표준 인터페이스입니다.\n",
    "    result = llm.invoke(messages)\n",
    "\n",
    "    # result는 보통 AIMessage 객체이며 .content에 텍스트가 들어 있습니다.\n",
    "    return result.content.strip()\n",
    "\n",
    "def call_llm_val(prompt: str) -> str:\n",
    "    \"\"\"\n",
    "    Upstage 모델을 한 번 호출하고 string만 돌려줍니다.\n",
    "    LangGraph 노드 안에서는 이 함수만 부릅니다.\n",
    "    \"\"\"\n",
    "    messages = [\n",
    "        SystemMessage(content=\"당신은 정중하고 정확하게 답변하는 전문가 어시스턴트입니다.\"),\n",
    "        HumanMessage(content=prompt),\n",
    "    ]\n",
    "\n",
    "    # invoke()는 ChatModel 표준 인터페이스입니다.\n",
    "    result = llm_validate.invoke(messages)\n",
    "\n",
    "    # result는 보통 AIMessage 객체이며 .content에 텍스트가 들어 있습니다.\n",
    "    return result.content.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7261ee3f",
   "metadata": {},
   "source": [
    "## 3. 노드 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "71865753",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 답변 초안 생성 노드\n",
    "def generate_answer(state: AgentState) -> AgentState:\n",
    "    \"\"\"\n",
    "    사용자 요청(user_input)을 보고 답변 초안(draft_answer)을 생성합니다.\n",
    "    loop_count도 함께 고려해서 '다시 시도'인지 아닌지 모델에게 알려줄 수 있습니다.\n",
    "    \"\"\"\n",
    "    user_input = state[\"user_input\"]\n",
    "    loop_count = state[\"loop_count\"]\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "당신은 사용자 질문에 답변을 작성하는 어시스턴트입니다.\n",
    "아래의 사용자 질문에 대해 명확하고 유용한 답변을 제시해 주세요.\n",
    "\n",
    "[시도 번호]: {loop_count}\n",
    "[사용자 질문]:\n",
    "{user_input}\n",
    "\n",
    "[현재까지의 답변 초안(있으면 참고, 없어도 무시해도 좋음)]:\n",
    "{state.get(\"draft_answer\") or \"(없음)\"}\n",
    "\"\"\"\n",
    "    draft = call_llm(prompt).strip()\n",
    "\n",
    "    # state 업데이트 후 반환\n",
    "    new_state = state.copy()\n",
    "    new_state[\"draft_answer\"] = draft\n",
    "    return new_state\n",
    "\n",
    "# 만족할만한 응답인지 검증하는 노드\n",
    "def evaluate_answer(state: AgentState) -> AgentState:\n",
    "    \"\"\"\n",
    "    draft_answer가 사용자가 만족할 만한지 LLM에게 물어보고,\n",
    "    'satisfied' 또는 'unsatisfied'로 태깅합니다.\n",
    "    \"\"\"\n",
    "    user_input = state[\"user_input\"]\n",
    "    draft_answer = state[\"draft_answer\"]\n",
    "\n",
    "    eval_prompt = f\"\"\"\n",
    "당신은 엄격한 리뷰어입니다.\n",
    "아래 기준으로만 판단해 주세요:\n",
    "\n",
    "1. 이 답변이 사용자의 실제 요구를 충족합니까?\n",
    "2. 논리적으로 틀린 내용이나 위험한 내용은 없습니까?\n",
    "3. 사용자가 실제로 \"이 정도면 됐다\"라고 할 법합니까?\n",
    "\n",
    "출력 형식은 JSON 한 줄로만 주세요:\n",
    "{{\n",
    "  \"verdict\": \"satisfied\" 또는 \"unsatisfied\",\n",
    "  \"reason\": \"왜 그렇게 판단했는지 한두 문장 설명\"\n",
    "}}\n",
    "\n",
    "[사용자 질문]\n",
    "{user_input}\n",
    "\n",
    "[제안된 답변]\n",
    "{draft_answer}\n",
    "\"\"\"\n",
    "    raw_eval = call_llm_val(eval_prompt)\n",
    "\n",
    "    # raw_eval을 파싱해야 합니다.\n",
    "    # 여기서는 최소 파서(매우 단순)만 작성하겠습니다.\n",
    "    import json\n",
    "    verdict = \"unsatisfied\"\n",
    "    reason = \"parse_failed\"\n",
    "    try:\n",
    "        parsed = json.loads(raw_eval.replace(\"```\",\"\").strip())\n",
    "        verdict = parsed.get(\"verdict\", \"unsatisfied\")\n",
    "        reason = parsed.get(\"reason\", \"\")\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    new_state = state.copy()\n",
    "    new_state[\"eval_result\"] = verdict\n",
    "    new_state[\"reasoning\"] = reason\n",
    "    new_state[\"loop_count\"] = state[\"loop_count\"] + 1\n",
    "    return new_state"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae1e01a7",
   "metadata": {},
   "source": [
    "## 4. 조건 분기 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "56fdc7b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def should_loop_or_finish(state: AgentState) -> str:\n",
    "    \"\"\"\n",
    "    LangGraph에서 conditional_edge에 사용됩니다.\n",
    "    반환값에 따라 다른 edge로 갑니다.\n",
    "    \"\"\"\n",
    "    verdict = state.get(\"eval_result\", \"unsatisfied\")\n",
    "    loops  = state.get(\"loop_count\", 1)\n",
    "\n",
    "    # 1. 루프 한계 먼저 검사합니다.\n",
    "    #    loop_count는 generate_answer에서 +1씩 증가하므로\n",
    "    #    loops가 max_loops 이상이면 그냥 끝냅니다.\n",
    "    print(loops)\n",
    "    if loops >= state.get(\"max_loops\",5):\n",
    "        return \"finish\"\n",
    "    \n",
    "    if verdict == \"satisfied\":\n",
    "        return \"finish\"\n",
    "    else:\n",
    "        return \"retry\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "051d50a8",
   "metadata": {},
   "source": [
    "## 5. 그래프 구축"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "05c1fd59",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, END\n",
    "\n",
    "# 그래프 객체 생성 (상태 타입 지정)\n",
    "workflow = StateGraph(AgentState)\n",
    "\n",
    "# 노드 등록\n",
    "workflow.add_node(\"generate_answer\", generate_answer)\n",
    "workflow.add_node(\"evaluate_answer\",  evaluate_answer)\n",
    "\n",
    "# 시작 노드 지정\n",
    "workflow.set_entry_point(\"generate_answer\")\n",
    "\n",
    "# 노드 간 기본 연결\n",
    "workflow.add_edge(\"generate_answer\", \"evaluate_answer\")\n",
    "\n",
    "# evaluate_answer 이후 분기:\n",
    "# - 만족: 종료(END)\n",
    "# - 불만족: 다시 generate_answer로\n",
    "workflow.add_conditional_edges(\n",
    "    \"evaluate_answer\",\n",
    "    should_loop_or_finish,\n",
    "    {\n",
    "        \"finish\": END,\n",
    "        \"retry\": \"generate_answer\",\n",
    "    },\n",
    ")\n",
    "\n",
    "# graph 컴파일\n",
    "app = workflow.compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe2bb65e",
   "metadata": {},
   "source": [
    "## 6. 그래프 실행 예시 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "21d4bc45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "----- 최종 답변 후보 -----\n",
      "심즈에서 심들의 기분을 최대치로 유지하는 것은 게임 플레이를 더욱 즐겁고 원활하게 진행하는 데 도움이 됩니다. 다음은 심들의 기분을 최대치로 유지하는 가장 효율적인 방법들입니다:\n",
      "\n",
      "1. **기본적인 필요 충족**:\n",
      "   - 배고픔, 목마름, 위생, 에너지, 행복 등 심들의 기본적인 필요를 정기적으로 충족시켜 주세요. 이를 위해 식사와 음료를 제공하고, 위생을 유지하며, 충분한 휴식을 취할 수 있도록 해줍니다.\n",
      "\n",
      "2. **행복한 환경 조성**:\n",
      "   - 심들의 성격에 맞는 편안한 가구를 배치하고, 조명과 색상을 통해 쾌적한 분위기를 만들어 주세요. 또한, 심들이 좋아하는 활동을 할 수 있는 공간을 마련하는 것도 중요합니다.\n",
      "\n",
      "3. **사회적 상호작용**:\n",
      "   - 심들이 친구나 가족과 상호작용하도록 장려하세요. 친구를 초대하여 파티를 열거나, 가족과 함께 게임을 하며 시간을 보내도록 합니다. 이는 심들의 사회적 필요를 충족시키고 기분을 높여줍니다.\n",
      "\n",
      "4. **취미와 직업**:\n",
      "   - 심들에게 취미 활동이나 직업을 부여하여 그들의 목표와 야망을 충족시키도록 합니다. 취미나 직업을 통해 심들은 성취감을 느끼고, 이는 기분을 높이는 데 기여합니다.\n",
      "\n",
      "5. **긍정적인 피드백**:\n",
      "   - 심들이 긍정적인 성과를 이루거나 좋은 행동을 할 때 칭찬하고 격려해 주세요. 이는 심들의 자신감을 높이고 기분을 개선하는 데 도움이 됩니다.\n",
      "\n",
      "6. **스트레스 관리**:\n",
      "   - 심들이 스트레스를 받지 않도록 주의 깊게 관리합니다. 스트레스를 유발할 수 있는 상황(예: 과도한 업무, 가족 갈등)을 피하고, 스트레스를 해소할 수 있는 활동(예: 운동, 음악 듣기)을 장려합니다.\n",
      "\n",
      "7. **관계 유지**:\n",
      "   - 심들이 서로 긍정적인 관계를 유지하도록 돕습니다. 사랑스러운 관계를 유지하거나, 친구와의 관계를 강화하면 심들의 기분이 더욱 높아질 수 있습니다.\n",
      "\n",
      "이러한 방법들을 통해 심들의 기분을 최대치로 유지하고, 게임 내에서 더욱 풍성한 경험을 즐길 수 있습니다. 각 심들의 성격과 선호도에 맞춰 조정하면서 게임을 진행하시면 더욱 효과적일 것입니다.\n",
      "\n",
      "----- 평가 정보 -----\n",
      "평가 결과: satisfied\n",
      "평가 사유: 답변은 게임 메커니즘과 심 심리 관리에 대한 실질적 전략을 제시하며, 위험한 내용이 없고 사용자가 요구한 '효율적인 방법'을 충분히 설명합니다.\n",
      "총 루프 횟수(추정): 1\n"
     ]
    }
   ],
   "source": [
    "# LangGraph는 \"스트리밍\" 스타일 step 호출도 있고, 한 번에 돌려서 최종 상태를 받을 수도 있습니다.\n",
    "# 여기서는 while 루프 없이 graph 자체에 맡깁니다.\n",
    "\n",
    "initial_state: AgentState = {\n",
    "    \"user_input\": \"심즈에서 심들의 기분을 최대치로 유지하는 가장 효율적인 방법은 뭐야?\",\n",
    "    \"draft_answer\": None,\n",
    "    \"eval_result\": None,\n",
    "    \"reasoning\": None,\n",
    "    \"loop_count\": 0,\n",
    "    \"max_loops\": 5,\n",
    "}\n",
    "\n",
    "# app.invoke는 상태를 받아서 끝날 때까지 돌리고 최종 상태를 반환합니다.\n",
    "final_state = app.invoke(initial_state)\n",
    "\n",
    "print(\"----- 최종 답변 후보 -----\")\n",
    "print(final_state[\"draft_answer\"])\n",
    "print()\n",
    "print(\"----- 평가 정보 -----\")\n",
    "print(\"평가 결과:\", final_state[\"eval_result\"])\n",
    "print(\"평가 사유:\", final_state[\"reasoning\"])\n",
    "print(\"총 루프 횟수(추정):\", final_state[\"loop_count\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f92efff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
